{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tq8K4z3cn8Mq"
      },
      "source": [
        "# V2LG RA Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FJn88jcn8JI"
      },
      "source": [
        "## - Aakash Yadav"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mounting Dataset"
      ],
      "metadata": {
        "id": "ZQjGdgjAn20t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5zzzFpUn667",
        "outputId": "a6faad64-84b4-406d-9c8f-4484a8dad60a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1H4c4OnmoeT6"
      },
      "outputs": [],
      "source": [
        "!unzip \"/content/gdrive/MyDrive/imageRanking/human_activity_retrieval_dataset.zip\" -d \"dataset\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHAEQxi8o6Rq",
        "outputId": "345df198-523d-4371-b4ed-2cf8b5b45d0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/dataset/human_activity_retrieval_dataset\n"
          ]
        }
      ],
      "source": [
        "cd /content/dataset/human_activity_retrieval_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdS-QljVpCJ0",
        "outputId": "05dcb70f-d5dc-4bec-80f6-e799a47c56d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mgallery\u001b[0m/  \u001b[01;34mquery_images\u001b[0m/  test_image_info.json  \u001b[01;34mtrain\u001b[0m/  train_image_info.json\n"
          ]
        }
      ],
      "source": [
        "ls"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries"
      ],
      "metadata": {
        "id": "_guGQPR9n73F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sEVX_hn3pDi-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "import cv2\n",
        "import imgaug as ia\n",
        "import imgaug.augmenters as iaa\n",
        "import random\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Exploration"
      ],
      "metadata": {
        "id": "Nam9crtVoA4u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "HOe7Y5rwpMQe"
      },
      "outputs": [],
      "source": [
        "# Load the training JSON file\n",
        "train_json_path = 'train_image_info.json'\n",
        "with open(train_json_path, 'r') as json_file:\n",
        "    train_data = json.load(json_file)\n",
        "\n",
        "# Load the test JSON file\n",
        "test_json_path = 'test_image_info.json'\n",
        "with open(test_json_path, 'r') as json_file:\n",
        "    test_data = json.load(json_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbAvTwXfpPh_",
        "outputId": "ee89aeb2-a5e4-4e9a-a0f7-8ff13227dd82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class: sitting, Count: 763\n",
            "Class: using_laptop, Count: 763\n",
            "Class: hugging, Count: 762\n",
            "Class: sleeping, Count: 761\n",
            "Class: drinking, Count: 763\n",
            "Class: clapping, Count: 763\n",
            "Class: dancing, Count: 760\n",
            "Class: cycling, Count: 763\n",
            "Class: calling, Count: 763\n",
            "Class: laughing, Count: 763\n",
            "Class: eating, Count: 764\n",
            "Class: fighting, Count: 764\n",
            "Class: listening_to_music, Count: 764\n",
            "Class: running, Count: 764\n",
            "Class: texting, Count: 763\n"
          ]
        }
      ],
      "source": [
        "labels = list(train_data.values())\n",
        "\n",
        "# Count the occurrences of each label\n",
        "label_counts = Counter(labels)\n",
        "for label, count in label_counts.items():\n",
        "    print(f\"Class: {label}, Count: {count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 15 classes, with approximately same number of images, so balanced dataset"
      ],
      "metadata": {
        "id": "FIQ-vNNtoECj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeEGNO71pS3D",
        "outputId": "e223546f-fe40-4ae7-9df5-cae53d0505a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Count: 11443\n"
          ]
        }
      ],
      "source": [
        "# Calculate the sum of all label counts\n",
        "total_count = sum(label_counts.values())\n",
        "print(f\"Total Count: {total_count}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_folder_path = 'train/'\n",
        "\n",
        "# Lists to store image widths and heights\n",
        "widths = []\n",
        "heights = []\n",
        "\n",
        "# Iterate through each image in train_data\n",
        "for image_filename in train_data.keys():\n",
        "    image_path = os.path.join(train_folder_path, image_filename)\n",
        "\n",
        "    with Image.open(image_path) as img:\n",
        "        image_size = img.size\n",
        "        widths.append(image_size[0])  # width\n",
        "        heights.append(image_size[1])  # height\n",
        "\n",
        "# Calculate minimum and maximum values for widths and heights\n",
        "min_width = min(widths)\n",
        "max_width = max(widths)\n",
        "min_height = min(heights)\n",
        "max_height = max(heights)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Minimum Width: {min_width}\")\n",
        "print(f\"Maximum Width: {max_width}\")\n",
        "print(f\"Minimum Height: {min_height}\")\n",
        "print(f\"Maximum Height: {max_height}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OST13C8nZGnA",
        "outputId": "34453b81-a0ca-40ba-c37e-0e8777146c3e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum Width: 84\n",
            "Maximum Width: 478\n",
            "Minimum Height: 84\n",
            "Maximum Height: 318\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Images vary a lot in their size, so resizing is required for better implementation of a CNN model."
      ],
      "metadata": {
        "id": "9AlK3HNWobSs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resizing the Images"
      ],
      "metadata": {
        "id": "Da8fHm7Gov9O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3bzC4AzNp_Dn"
      },
      "outputs": [],
      "source": [
        "target_size = (256, 256)\n",
        "for folder_path in [\"gallery/\", \"train/\", \"query_images/\"]:\n",
        "    for filename in os.listdir(folder_path):\n",
        "        # Read the original image\n",
        "        image_path = os.path.join(folder_path, filename)\n",
        "        img = cv2.imread(image_path)\n",
        "\n",
        "        # Resize the image\n",
        "        resized_img = cv2.resize(img, target_size, interpolation=cv2.INTER_AREA)\n",
        "\n",
        "        # Save the resized image with the same filename\n",
        "        cv2.imwrite(image_path, resized_img)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definig the CNN Architecture"
      ],
      "metadata": {
        "id": "6EIjEpdmoycM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
      ],
      "metadata": {
        "id": "0Fwvkg0VZ1fr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAVvj9R_pWUc",
        "outputId": "03ec2aab-1f83-4804-9ef1-07577960c163"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 254, 254, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 127, 127, 32)      0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 125, 125, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 62, 62, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 60, 60, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 30, 30, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 115200)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               14745728  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 15)                1935      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14840911 (56.61 MB)\n",
            "Trainable params: 14840911 (56.61 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(15, activation='softmax'))\n",
        "model.summary()\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Class Data Folders"
      ],
      "metadata": {
        "id": "KvEmI7pIo4QU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "G-0ElD3_t_vn"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists('class_data'):\n",
        "    os.makedirs('class_data')\n",
        "class_data_dict = {}\n",
        "for filename, label in train_data.items():\n",
        "    class_subfolder_path = os.path.join('class_data', label)\n",
        "    if not os.path.exists(class_subfolder_path):\n",
        "        os.makedirs(class_subfolder_path)\n",
        "    image_path = os.path.join('train/', filename)\n",
        "    new_image_path = os.path.join(class_subfolder_path, filename)\n",
        "    os.rename(image_path, new_image_path)\n",
        "    if label not in class_data_dict:\n",
        "        class_data_dict[label] = [filename]\n",
        "    else:\n",
        "        class_data_dict[label].append(filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Images from \"train\" Folder"
      ],
      "metadata": {
        "id": "JJkPnBjRpDG6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cGEXZIxv7Ey",
        "outputId": "e43ead35-7bb8-4751-acab-6f035f1eb588"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 11443 images belonging to 15 classes.\n"
          ]
        }
      ],
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "image_paths = []\n",
        "labels = []\n",
        "for filename, label in train_data.items():\n",
        "    image_paths.append(os.path.join('class_data', label, filename))\n",
        "    labels.append(label)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Create a label encoder\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "encoder.fit(labels)\n",
        "encoded_labels = encoder.transform(labels)\n",
        "\n",
        "# Create the image data generator\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load the training data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    'class_data',\n",
        "    target_size=(256, 256),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    epochs=10\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-kg25iPkFAI",
        "outputId": "fa5cc7e5-1201-46d0-e199-503fffcfe98f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "358/358 [==============================] - 32s 89ms/step - loss: 2.5640 - accuracy: 0.1531\n",
            "Epoch 2/10\n",
            "358/358 [==============================] - 30s 85ms/step - loss: 2.1423 - accuracy: 0.3060\n",
            "Epoch 3/10\n",
            "358/358 [==============================] - 28s 78ms/step - loss: 1.6804 - accuracy: 0.4576\n",
            "Epoch 4/10\n",
            "358/358 [==============================] - 32s 88ms/step - loss: 1.0239 - accuracy: 0.6751\n",
            "Epoch 5/10\n",
            "358/358 [==============================] - 34s 96ms/step - loss: 0.4181 - accuracy: 0.8702\n",
            "Epoch 6/10\n",
            "358/358 [==============================] - 30s 84ms/step - loss: 0.1355 - accuracy: 0.9608\n",
            "Epoch 7/10\n",
            "358/358 [==============================] - 30s 84ms/step - loss: 0.0651 - accuracy: 0.9821\n",
            "Epoch 8/10\n",
            "358/358 [==============================] - 31s 86ms/step - loss: 0.0798 - accuracy: 0.9774\n",
            "Epoch 9/10\n",
            "358/358 [==============================] - 30s 84ms/step - loss: 0.0598 - accuracy: 0.9823\n",
            "Epoch 10/10\n",
            "358/358 [==============================] - 30s 84ms/step - loss: 0.0502 - accuracy: 0.9837\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a482f47ee30>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "7nduF7sLv5ol"
      },
      "outputs": [],
      "source": [
        "# Save the Model\n",
        "model.save('cnn_model.keras')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import average_precision_score, label_ranking_average_precision_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.applications.resnet50 import preprocess_input\n",
        "\n",
        "labels = list(test_data.values())\n",
        "\n",
        "# Use LabelEncoder to convert string labels to numerical labels\n",
        "label_encoder = LabelEncoder()\n",
        "numerical_labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# Load and preprocess gallery and query images\n",
        "def load_and_preprocess_image(folder, filename):\n",
        "    img = cv2.imread(os.path.join(folder, filename))\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # OpenCV uses BGR, convert to RGB\n",
        "    img_array = preprocess_input(np.expand_dims(img, axis=0))\n",
        "    return img_array\n",
        "\n",
        "gallery_images = [load_and_preprocess_image(\"gallery\", filename) for filename in os.listdir(\"gallery\")]\n",
        "query_images = [load_and_preprocess_image(\"query_images\", filename) for filename in os.listdir(\"query_images\")]\n",
        "\n",
        "# Stack the image arrays\n",
        "gallery_images = np.vstack(gallery_images)\n",
        "query_images = np.vstack(query_images)\n",
        "\n",
        "# Get the model predictions for query images on the gallery\n",
        "query_predictions = model.predict(query_images)\n",
        "\n",
        "# Calculate Mean Average Precision (mAP) at K={1, 10, 50} and mean rank\n",
        "k_values = [1, 10, 50]\n",
        "for k in k_values:\n",
        "    average_precision = 0.0\n",
        "    mean_rank = 0.0\n",
        "    for i in range(len(query_predictions)):\n",
        "        # Sort the gallery images based on similarity scores\n",
        "        sorted_indices = np.argsort(query_predictions[i])[::-1]\n",
        "\n",
        "        # Get the top k predictions\n",
        "        top_k_indices = sorted_indices[:k]\n",
        "\n",
        "        # Check if the true label is in the top k predictions\n",
        "        if numerical_labels[i] in numerical_labels[top_k_indices]:\n",
        "            precision = 1.0\n",
        "            rank = np.where(numerical_labels[top_k_indices] == numerical_labels[i])[0][0] + 1\n",
        "        else:\n",
        "            precision = 0.0\n",
        "            rank = k + 1\n",
        "\n",
        "        average_precision += precision / k\n",
        "        mean_rank += rank\n",
        "\n",
        "    mean_average_precision = average_precision / len(query_predictions)\n",
        "    mean_rank /= len(query_predictions)\n",
        "\n",
        "    print(f\"mAP@{k}: {mean_average_precision:.4f}\")\n",
        "    print(f\"Mean Rank: {mean_rank:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFUwoAlvmqgs",
        "outputId": "907eac2b-0287-4945-8718-1714d12e8ac2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 24ms/step\n",
            "mAP@1: 0.4467\n",
            "Mean Rank: 1.55\n",
            "mAP@10: 0.0447\n",
            "Mean Rank: 6.53\n",
            "mAP@50: 0.0089\n",
            "Mean Rank: 28.67\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}